{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c820a94",
   "metadata": {},
   "source": [
    "#### Pre-Lecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a91e0",
   "metadata": {},
   "source": [
    "1. \n",
    "- The main difference between simple and multiple linear regression is, SLR is the relation between two variables and, MLR is the relation between at least one independent variable and a dependent variable.\n",
    "- The difference between a continuous and indicator variable is, a continuous variable is measured on a continuous scale, used in SLR when dependent variable is continuous. The indicator variable represents a categorical variable and is used in SLR, when dependent variable is binary.\n",
    "- When a single indicator variable is introduced with a continuous one in MLR, the model is being extended to account fot both quantitative and qualitative factors that affect the dependent variable.\n",
    "- In MLR, if there is an added interaction between a continuous variable and a binary variable, the relationship between these variable depends on teh value of the indicator. This helps model more complex relations/\n",
    "- When an indicator variable is included in a MLR model that is influenced by a non-binary variable, it creates a model that accounts for the complications and differences within the variables and there relationships. These can estimate different intercepts for teh groupd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c098e",
   "metadata": {},
   "source": [
    "2. In this scenario, the outcome variable is the sales, customer engagement adn brand awareness. The predictor variable is the money spent on advertisments. Potential interactions to include are, interaction between TV ads and other online ads, interaction between ad time and how much spent, interaction between customer demography and ad spent.\n",
    "To use the SLR you set y(sales) = B0(initial value)+B1(slope) * x($ spent)+e (error term). To use the MLR you set y(sales0 = B0(Intercept)+B1(coefficient for x1)*x1(first predictor)+B2(coefficient for x2)*x2(second predictor)+E(error term). The key differences are one is a model without interaction, meaning the TV money and Online money on sales are ind. of each pther. The other model assumes there is a combined effect of money spent on TVs and online which allows for flexibility and is useful especially in a non-linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201e515",
   "metadata": {},
   "source": [
    "3. ChatGPT Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ac8c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.018023687428230007\n",
      "            Iterations: 186\n",
      "            Function evaluations: 186\n",
      "            Gradient evaluations: 186\n",
      "                             Logit Regression Results                             \n",
      "==================================================================================\n",
      "Dep. Variable:     high_social_connection   No. Observations:                  800\n",
      "Model:                              Logit   Df Residuals:                      794\n",
      "Method:                               MLE   Df Model:                            5\n",
      "Date:                    Wed, 13 Nov 2024   Pseudo R-squ.:                  0.9865\n",
      "Time:                            04:18:21   Log-Likelihood:                -5.6006\n",
      "converged:                           True   LL-Null:                       -413.80\n",
      "Covariance Type:                nonrobust   LLR p-value:                3.277e-174\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               36.2778      8.967      4.046      0.000      18.704      53.852\n",
      "C(Legendary)[T.True]          0        nan        nan        nan         nan         nan\n",
      "C(Generation)[T.2]            0        nan        nan        nan         nan         nan\n",
      "C(Generation)[T.3]       0.3029      1.521      0.199      0.842      -2.678       3.284\n",
      "C(Generation)[T.4]       0.8227      1.473      0.558      0.577      -2.065       3.710\n",
      "C(Generation)[T.5]      -0.3908      1.723     -0.227      0.821      -3.768       2.986\n",
      "C(Generation)[T.6]       0.3601      1.470      0.245      0.807      -2.521       3.241\n",
      "log_Attack_scaled       50.0289     11.942      4.189      0.000      26.622      73.436\n",
      "========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.88 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Replace this with the actual URL of your dataset\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"  # Example dataset URL\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(url).fillna('None')  # Fill missing values with 'None' or another strategy\n",
    "\n",
    "# Example: Create a binary variable for high social connection (based on Attack > 50)\n",
    "data['high_social_connection'] = (data['Attack'] > 50).astype(int)  # Adjust as needed\n",
    "\n",
    "# Log-transform 'Attack' to reduce the effect of extreme values (if applicable)\n",
    "data['log_Attack'] = np.log(data['Attack'] + 1)  # Use log(Attack + 1) to avoid log(0) issues\n",
    "\n",
    "# Standardize the 'log_Attack' column\n",
    "scaler = StandardScaler()\n",
    "data['log_Attack_scaled'] = scaler.fit_transform(data[['log_Attack']])\n",
    "\n",
    "# Logistic regression model specification formula (removed quadratic term, added log-transformed Attack)\n",
    "logistic_formula = 'high_social_connection ~ log_Attack_scaled + C(Legendary) + C(Generation)'\n",
    "\n",
    "# Fit the logistic regression model using regularization (L1 or L2)\n",
    "try:\n",
    "    log_reg_fit = smf.logit(logistic_formula, data=data).fit_regularized(method='l1', alpha=0.1)  # L1 regularization with a small penalty\n",
    "    # Show the summary of the logistic regression fit\n",
    "    print(log_reg_fit.summary())\n",
    "except Exception as e:\n",
    "    print(\"Error fitting the model:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1a65b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load your dataset (replace 'your_data.csv' with your actual dataset path)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual dataset path)\n",
    "data = pd.read_csv('your_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589300c3",
   "metadata": {},
   "source": [
    "4. The apparent contradiction is rooted in the comparison of the metrics that measure different aspect's of the model's performance - how well the model fits the data vs. reliability of ind. predictor effects.\"The model only explains 17.6% of the variability in the data, refers to the model's R^2, measuring the variability in the outcome. An R^2 value  of .176 means that much of the variability is unexplained by the model and there are other vactors affecting the outcome that have not been accounted for by the model. Secondly, \"many ofhte coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis\", means that ind. predictors have statistically sig. effects on the outcome. Larger coefficients and low p-values indicate that there is a high chance, these predictors have a strong relationship with the oucoem variable.\n",
    "This situation is rooted in teh fact that strong ind. affects do no tnecessarily imply a good overall model fit. This is because the outcome is influenced by many other varuables that aren't included in the model or the outcome variable has a high inherent varaibility. So, these metrics are complementary rather than contradictory as a low R^2 illustrates the model does not capture the overall variability and the large sig. coefficients highlight the predicotrs have strong, sig. relationships with the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a9101",
   "metadata": {},
   "source": [
    "ChatGPT Summary:Statistical Interpretation: We explored the apparent contradiction between a low R ^2value (indicating the model explains 17.6% of the variability) and large, significant coefficients (indicating strong predictor effects). These metrics address different aspects: \n",
    "𝑅^2 reflects the overall explanatory power of the model, while coefficients and p-values assess the significance of individual predictors.\n",
    "Code Explanation: We reviewed Python code that loads Pokémon data, defines and fits OLS regression models using statsmodels, and summarizes the results. The error you encountered (SyntaxError: incomplete input) was due to a missing closing parenthesis in the summary() function call, which was fixed by completing the call with model2_fit.summary().\n",
    "ChatGPT Link:https://chatgpt.com/c/6734f632-e170-8013-bc9d-c94e074b45e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188ee2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ab7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     HP   R-squared:                       0.176\n",
      "Model:                            OLS   Adj. R-squared:                  0.164\n",
      "Method:                 Least Squares   F-statistic:                     15.27\n",
      "Date:                Wed, 13 Nov 2024   Prob (F-statistic):           3.50e-27\n",
      "Time:                        19:17:26   Log-Likelihood:                -3649.4\n",
      "No. Observations:                 800   AIC:                             7323.\n",
      "Df Residuals:                     788   BIC:                             7379.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
      "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
      "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
      "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
      "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
      "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
      "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
      "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
      "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
      "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
      "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
      "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
      "==============================================================================\n",
      "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
      "Skew:                           1.684   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url)\n",
    "\n",
    "# Define and fit the models\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "# Fit and summarize the second model\n",
    "model2_fit = model2_spec.fit()\n",
    "print(model2_fit.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392e1bb",
   "metadata": {},
   "source": [
    "#### Post-Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f949638",
   "metadata": {},
   "source": [
    "5. The first cell imports the data and splits it into training and testing sets. It then calculates the size for the traingin set (50% of data) and replaces any NaN values with None (type 2 column). IT sets a random seed to make sure the same results are produced whenever the code is run one for training and one for testing. \n",
    "The second cell specifies an OLS regression model where HP is a dependent variable and Attack and Defense are the ind. varaibles. It fits the dataset into training model and generates display summary of the model, including coefficients, p-values, R^2 and other statistical numbers. \n",
    "The third cell uses the fitted model to predict HP values from the test set and uses the actual values in comparison. This prints the R^2 value from the training set, essentially measuring how well the data fits and finally, it computes an out of sampl R^2, measuring the model's performance on test data, used correlatoin coefficient between predictd and actual values.\n",
    "The fourth cell is more complex and there are four ind. variable to one dep. variable. So, it ultimately extends the formula by adding interactions with special defense and special attack using the OLS model to the training dataset. Ultimately, it creates a summary of the complex model, illustrating how accurately the predictors explain HP variance.\n",
    "The fifth cell uses this fitted model to predict HP values for the test set, extracting the actual values for this comparison and then printing out a R^2 valuye for the more complex model. This also calculates the out of sample R^\"2 for this model, measuring how well the model performs in the data for the test set.\n",
    "Overall\n",
    "The first model is a simple linear regression model while the second one is more complex as it involves more interactions between multiple predictors. The in sample R^2 shows how well the the training data fits the model and the out sample shows how well the model fits to unseen data. The more complex model probably has a higher in sample R^2 due to more predictors and interactions but may overfit it out sample R^2 is lower indicating it performs well only if it sees the data. It also summarizes the key statistics like p-values, coefficients adn R^2 values helping to evaluate the relationships and understand the real world predictive power of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d8ccc",
   "metadata": {},
   "source": [
    "ChatGPT Summary:The code evaluates model performance by comparing in-sample and out-of-sample 𝑅^2 values. In-sample 𝑅^2 measures how well the model fits the training data, while out-of-sample 𝑅^2evaluates how well the model generalizes to unseen test data. A large discrepancy between these values suggests overfitting, where the model performs well on the training data but poorly on new data. The goal is to ensure that both 𝑅^2 values are similar, indicating that the model generalizes well and is not overfitting to the training set.\n",
    "Chat GPT Link:https://chatgpt.com/c/6734f632-e170-8013-bc9d-c94e074b45e7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ff5ca",
   "metadata": {},
   "source": [
    "6. Essentially the (model4_linear_form) creates a new predictor varaibles by including all of the interactions. This results in a very large design matrix (model4_spec.exog), with several columns to represent all these interactions. Multicollinearity is a multiple linear regression model with a minimum of two ind. variables that are highly correlated with each other. In this case, interactions between defense and attack are closely related therefore casuign redundancy in the model. This leads to unstable coefficient estimate becasue the model struggles to distinguish the individual relations from each other, leading to overfitting. Ultimately, this hinders the model's ability to understand and accurately synthesize new data resulting in a poor out of sample performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae507ba",
   "metadata": {},
   "source": [
    "ChatGPT Summary:Multicollinearity occurs when two or more predictors in a regression model are highly correlated with each other. This redundancy makes it difficult for the model to distinguish the individual effect of each predictor, leading to unstable coefficient estimates, inflated standard errors, and poor model interpretability. It can cause overfitting, where the model performs well on training data but poorly on new data. Multicollinearity can be detected using a correlation matrix, Variance Inflation Factor (VIF), or the condition number. It can be addressed by removing correlated predictors, combining them, or using regularization techniques like Ridge or Lasso regression.\n",
    "    Link: https://chatgpt.com/c/6734f632-e170-8013-bc9d-c94e074b45e7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0ef42",
   "metadata": {},
   "source": [
    "7. \n",
    "Model 5 builds on Model 3 as it retains predictors such as Attack and Defense but expands through the addition of new varaibles like speed and special defense. THis feature enables the model to capture several dimensions of the HP prediction without complex interactions, making it simpler. Model 5 builds on Model 4 by ultimately simplifying the structure, improving interpretability and reducing multicollinearity.\n",
    "Model 6 builds of Model 5 as it narrows down to only the most significant predictors (Attack, Speed, Sp. Defense, Special Attack). It also only uses necessary indicators. It furthers enhances interpretability as it reduces variables with the strongest evidence and as a result it has more reliable and relevant predictors.\n",
    "Model 7 builds of Model 6 a it brings back interaction terms but selectively so. This means it meaninfully contributes to predicting the HP based on exploratory data. This avoids complexity and multicollinearity from Models 3 & 4. It is also a more centered and scaled version indicating there is minimal if any overfitting due to high intercorrelations, achieving a balance between complexity and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f331a2",
   "metadata": {},
   "source": [
    "ChatGPT Summary:We discussed multiple linear regression models using Pokémon dataset features. Key points include:\n",
    "\n",
    "Model Development: Models (like Model 3, Model 4, etc.) were developed with increasing complexity by adding more predictor variables such as Attack, Defense, Speed, Legendary status, and various stat categories like Sp. Atk and Sp. Def.\n",
    "\n",
    "Overfitting and Multicollinearity: We explored how overly complex models, especially with high multicollinearity among predictors, can overfit to the training data, reducing their ability to generalize to unseen data.\n",
    "\n",
    "Generalizability: We compared \"in-sample\" and \"out-of-sample\" performance metrics (like R-squared) to assess how well models generalize beyond the training data. Multicollinearity and model complexity were found to negatively affect generalizability.\n",
    "\n",
    "Feature Selection: We identified relevant features (core stats, categorical variables, and interactions) to improve model prediction, with a focus on balancing complexity and generalizability.\n",
    "\n",
    "Overall, we examined how to build predictive models, diagnose overfitting, and select appropriate features for better generalization.\n",
    "Link: https://chatgpt.com/c/6734f632-e170-8013-bc9d-c94e074b45e7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fda20",
   "metadata": {},
   "source": [
    "8. EXPLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee76671",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_pokeaman_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m pokeaman \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_pokeaman_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your actual file path\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Define model linear form (as an example, modify this based on your model)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_linear_form \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHP ~ Attack + Defense + Speed + Legendary + Q(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSp. Def\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) + Q(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSp. Atk\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_pokeaman_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "pokeaman = pd.read_csv('path_to_pokeaman_data.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define model linear form (as an example, modify this based on your model)\n",
    "model_linear_form = 'HP ~ Attack + Defense + Speed + Legendary + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "\n",
    "# Set up the number of iterations for the loop\n",
    "num_iterations = 100\n",
    "in_sample_r_squared = []\n",
    "out_of_sample_r_squared = []\n",
    "\n",
    "# For loop to create multiple splits and compute R-squared\n",
    "for _ in range(num_iterations):\n",
    "    # Randomly split the data into training and testing sets\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model_spec = smf.ols(formula=model_linear_form, data=pokeaman_train)\n",
    "    model_fit = model_spec.fit()\n",
    "\n",
    "    # Make predictions on the training and test data\n",
    "    yhat_train = model_fit.predict(pokeaman_train)\n",
    "    yhat_test = model_fit.predict(pokeaman_test)\n",
    "\n",
    "    # Actual target values\n",
    "    y_train = pokeaman_train['HP']\n",
    "    y_test = pokeaman_test['HP']\n",
    "\n",
    "    # Compute R-squared for in-sample and out-of-sample data\n",
    "    in_sample_r_squared.append(model_fit.rsquared)\n",
    "    out_of_sample_r_squared.append(np.corrcoef(y_test, yhat_test)[0, 1]**2)\n",
    "\n",
    "# Visualize the R-squared values\n",
    "plt.plot(in_sample_r_squared, label='In-sample R-squared')\n",
    "plt.plot(out_of_sample_r_squared, label='Out-of-sample R-squared')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('R-squared')\n",
    "plt.title('In-sample vs Out-of-sample R-squared over multiple iterations')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc69323",
   "metadata": {},
   "source": [
    "9. The cells of code involve a series of steps to train different models (simple & complex) on subsets of the data and how to evaluate their performance in terms of in-sample and out-of-sample R^2, as well as their ability to predict accurate subsets of the Pokeaman Set.\n",
    "The key ideas are simplicity vs. complexity, generalization and overfitting, and model interpretability.\n",
    "Model7_fit is more complex than model6_fit, with a larger set of predicotr variables and interaction terms. Model7_fits performs better in terms out-of-sample prediciton however, model6_fit has stronger evidence for p-values. Model7_fit may fail to accurately predict new data because it has learned idiosyncratic patterns from the fata whereas Model6_fit will be simpler and have better generalizability because it is less likely to capture spurious patterns. The more simpler a model is, the more reliable interpretation is offered because stakeholders are more likely to trust the results if they think htey know exactly what affects the ouctome variables. \n",
    "\n",
    "R^2 essentially measures how well the model fits the training data. Out-of-sample R^2 measures how well the model generalizes to new, unseen data which is important to assess whether the model is underfitting or overfitting. By testing models on different generations you are able to see how well it applies to the real-world.\n",
    "The ultimate purpose of this code is to assess the model's generalizability across different subsets of data, test how well Model7 and Model6 perform, highlight the trade-off between complexity and performance and liiustrate how sequential data collection may affect a model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988b0c6",
   "metadata": {},
   "source": [
    "ChatGPT Summary:The code assesses two models—model7 (more complex) and model6 (simpler)—for their predictive accuracy and generalizability using Pokémon data divided by generations. By training on past generations and testing on future ones, it simulates real-world sequential data prediction. Both in-sample (on training data) and out-of-sample R-squared (on unseen generations) are calculated to evaluate model performance. While model7 shows higher predictive power, its complexity may lead to overfitting, making it less generalizable and harder to interpret compared to the simpler, more robust model6. This highlights the trade-off between model performance and interpretability, emphasizing that simpler models may be preferable in practice for better consistency and clarity.\n",
    "    Link: https://chatgpt.com/c/6734f632-e170-8013-bc9d-c94e074b45e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b84476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
